{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset\n",
    "    This dataset contains 28x28 grayscale images of digits from 0 to 9. In the train csv file, there are 42000 examples/images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/netbrainml/nbml.git\r\n",
      "  Cloning https://github.com/netbrainml/nbml.git to /tmp/pip-req-build-djsnmf4m\r\n",
      "  Running command git clone -q https://github.com/netbrainml/nbml.git /tmp/pip-req-build-djsnmf4m\r\n",
      "Building wheels for collected packages: nbml\r\n",
      "  Building wheel for nbml (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for nbml: filename=nbml-0.0.1-cp36-none-any.whl size=11985 sha256=43521fcea8cfefa03648fec3b8f911db413985922de04cae90760d8e6c381774\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0vssqhle/wheels/3a/b1/27/4431be29eb1fbe8f0912364e44fecc078167c19415ed958b11\r\n",
      "Successfully built nbml\r\n",
      "Installing collected packages: nbml\r\n",
      "Successfully installed nbml-0.0.1\r\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 19.2.2 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/netbrainml/nbml.git\n",
    "from nbml.workshops.mnist.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put the data into the model, we need to wrap the numpy arrays as torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arg_0: torch.Size([37800, 784])\n",
      "arg_1: torch.Size([4200, 784])\n",
      "arg_2: torch.Size([37800])\n",
      "arg_3: torch.Size([4200])\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = getMNIST(\"../input/train.csv\")\n",
    "x_train, x_test = torch.Tensor(x_train), torch.Tensor(x_test)\n",
    "y_train, y_test = torch.Tensor(y_train), torch.Tensor(y_test)\n",
    "shapes(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are DataLoaders?\n",
    "    Allow us to use generators that zip features and targets in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "tdl = DataLoader(TensorDataset(x_train, y_train), batch_size=256, shuffle=True)\n",
    "vdl = DataLoader(TensorDataset(x_test, y_test), batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class SLP(BasicTrainableClassifier):\n",
    "    def __init__(self,in_c, out_c, num_units):\n",
    "        super().__init__()\n",
    "        self.slp = nn.Sequential(nn.Linear(in_c, num_units),\n",
    "                                 nn.Linear(num_units, out_c))\n",
    "    def __call__(self,x):\n",
    "        return self.slp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look inside Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Linear??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.linear??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of our SLP class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SLP(\n",
       "  (crit): CrossEntropyLoss()\n",
       "  (slp): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slp_m = SLP(784, 10, 512).cuda() #.cpu() to use CPU... .cuda() uses GPU, which allows for parallel processing which is much faster\n",
    "slp_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is BasicTrainableClassifier?\n",
    "    A parent class we wrote that has some functions that may be useful.\n",
    "    You can write your own class, and notice the parent class of BasicTrainableClassifier (nn.Module).\n",
    "    nn.Module is a class that PyTorch created that has many functionalities, acting as the base class for all machine learning models.\n",
    "    All you really need to write is the __init__() and forward().\n",
    "    In the __init__(), call the superclass's dunder init by super().__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasicTrainableClassifier??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slp_m(torch.Tensor(x_train[:20]).cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 25/148 [00:00<00:00, 242.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 244.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: (V:0.9182515565086814, T:0.9161903254083685), Loss: (V:0.29042427855379443, T:0.29330215079558863)\n"
     ]
    }
   ],
   "source": [
    "slp_m.fit(tdl, valid_ds=vdl, epochs=1,\n",
    "            cbs=True, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(BasicTrainableClassifier):\n",
    "    def __init__(self, ls):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(*[nn.Sequential(nn.Linear(*n), nn.ReLU()) for n in ls])\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(start, hs, end, step):\n",
    "    lse = [*list(range(hs, end, -step)), end]\n",
    "    return list(zip([start,*lse[:]], [*lse[:], end]))[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(784, 512), (512, 256), (256, 10)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = get_layers(784,512,10,256)\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 25/148 [00:00<00:00, 243.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 248.28it/s]\n",
      " 16%|█▌        | 23/148 [00:00<00:00, 223.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: (V:0.6753393692128798, T:0.6721087718332136), Loss: (V:0.82520250713124, T:0.842455328719036)\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 245.58it/s]\n",
      " 17%|█▋        | 25/148 [00:00<00:00, 242.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: (V:0.6788744365467745, T:0.679912474107098), Loss: (V:0.8000558404361501, T:0.7962220335328901)\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 248.49it/s]\n",
      " 17%|█▋        | 25/148 [00:00<00:00, 243.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: (V:0.6856440901756287, T:0.6874007099383587), Loss: (V:0.7735241967089036, T:0.7605302390214559)\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 243.99it/s]\n",
      " 18%|█▊        | 26/148 [00:00<00:00, 251.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: (V:0.6905048103893504, T:0.6902160253879186), Loss: (V:0.7489228774519527, T:0.7473121869402963)\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:00<00:00, 236.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: (V:0.6911764705882353, T:0.6915972893302506), Loss: (V:0.7444819176898283, T:0.7331306571896011)\n"
     ]
    }
   ],
   "source": [
    "mlp_m = MLP(ls).cuda()\n",
    "mlp_m.fit(tdl, valid_ds=vdl, epochs=5,\n",
    "            cbs=True, learning_rate=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
